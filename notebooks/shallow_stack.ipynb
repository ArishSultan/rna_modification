{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-02T08:35:03.783371Z",
     "start_time": "2023-08-02T08:35:03.775026Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from src.model import lr\n",
    "from src.data import load_psi, Species\n",
    "from src.experiment import Experiment\n",
    "from src.experiment.report import Report\n",
    "from src.features.encodings import binary\n",
    "\n",
    "from src.experiment.reports.latex_report import generate_kfold_latex_report, generate_latex_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "human_ds_train = load_psi(Species.human)\n",
    "human_ds_test = load_psi(Species.human, independent=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T08:10:22.840114Z",
     "start_time": "2023-08-02T08:10:22.827383Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "encoder = binary.EncoderImp()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T08:10:25.399216Z",
     "start_time": "2023-08-02T08:10:25.380796Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "sklearn_experiment = Experiment(lr.Factory(), human_ds_test, human_ds_train, encoder)\n",
    "sklearn_report = sklearn_experiment.run()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T07:10:35.048173Z",
     "start_time": "2023-07-31T07:10:34.963114Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note: Running TeX ...\n",
      "note: Rerunning TeX because \"lr_kfold_binary_human.aux\" changed ...\n",
      "note: Running xdvipdfmx ...\n",
      "note: Writing `lr_kfold_binary_human.pdf` (69.17 KiB)\n",
      "note: Skipped writing 1 intermediate files (use --keep-intermediates to keep them)\n",
      "note: Running TeX ...\n",
      "note: Rerunning TeX because \"lr_binary_human.aux\" changed ...\n",
      "note: Running xdvipdfmx ...\n",
      "note: Writing `lr_binary_human.pdf` (25.75 KiB)\n",
      "note: Skipped writing 1 intermediate files (use --keep-intermediates to keep them)\n"
     ]
    }
   ],
   "source": [
    "generate_kfold_latex_report(sklearn_report['train'], 'lr_kfold_binary_human', Path('.'), True)\n",
    "generate_latex_report(sklearn_report['test'], 'lr_binary_human', Path('.'), True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T07:10:42.125373Z",
     "start_time": "2023-07-31T07:10:35.038804Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# imp_x = x[map(lambda _: f'binary_{_}', [46, 36, 44, 77, 45, 49, 3])]\n",
    "# imp_x_test = x_test[map(lambda _: f'binary_{_}', [46, 36, 44, 77, 45, 49, 3])]\n",
    "# regressor2 = LogisticRegressionCV()\n",
    "# regressor2.fit(imp_x, y)\n",
    "# \n",
    "# generate_report(\n",
    "#     {'train': ModelReport.generate(regressor2, imp_x, y), 'test': ModelReport.generate(regressor2, imp_x_test, y_test)},\n",
    "#     Path('lr_feature_selection'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tensorflow Portion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.src.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "encoder = binary.Encoder()\n",
    "x = encoder.fit_transform(human_ds_train.samples)\n",
    "y = human_ds_train.targets\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the TensorFlow model\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=3, restore_best_weights=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T08:10:27.549129Z",
     "start_time": "2023-08-02T08:10:27.468201Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 744us/step - loss: 0.7024 - accuracy: 0.5101\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 572us/step - loss: 0.6781 - accuracy: 0.5518\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 595us/step - loss: 0.6611 - accuracy: 0.5997\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 571us/step - loss: 0.6465 - accuracy: 0.6351\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 508us/step - loss: 0.6329 - accuracy: 0.6503\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 520us/step - loss: 0.6218 - accuracy: 0.6692\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 493us/step - loss: 0.6119 - accuracy: 0.6894\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 499us/step - loss: 0.6029 - accuracy: 0.6869\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 512us/step - loss: 0.5944 - accuracy: 0.7008\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 520us/step - loss: 0.5845 - accuracy: 0.7058\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 597us/step - loss: 0.5771 - accuracy: 0.7159\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 605us/step - loss: 0.5713 - accuracy: 0.7222\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 538us/step - loss: 0.5630 - accuracy: 0.7273\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 525us/step - loss: 0.5581 - accuracy: 0.7247\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 517us/step - loss: 0.5523 - accuracy: 0.7184\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 510us/step - loss: 0.5445 - accuracy: 0.7323\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 511us/step - loss: 0.5390 - accuracy: 0.7361\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 538us/step - loss: 0.5332 - accuracy: 0.7361\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 509us/step - loss: 0.5290 - accuracy: 0.7437\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 525us/step - loss: 0.5206 - accuracy: 0.7538\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 477us/step - loss: 0.5150 - accuracy: 0.7576\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 523us/step - loss: 0.5092 - accuracy: 0.7525\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 524us/step - loss: 0.5029 - accuracy: 0.7652\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 559us/step - loss: 0.4974 - accuracy: 0.7765\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 538us/step - loss: 0.4908 - accuracy: 0.7740\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 509us/step - loss: 0.4845 - accuracy: 0.7778\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 556us/step - loss: 0.4784 - accuracy: 0.7904\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 511us/step - loss: 0.4735 - accuracy: 0.7841\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 522us/step - loss: 0.4659 - accuracy: 0.7980\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 515us/step - loss: 0.4586 - accuracy: 0.8194\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 581us/step - loss: 0.4514 - accuracy: 0.8207\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 543us/step - loss: 0.4453 - accuracy: 0.8258\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 528us/step - loss: 0.4387 - accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 520us/step - loss: 0.4320 - accuracy: 0.8396\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 475us/step - loss: 0.4255 - accuracy: 0.8460\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 518us/step - loss: 0.4189 - accuracy: 0.8535\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 512us/step - loss: 0.4123 - accuracy: 0.8535\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 542us/step - loss: 0.4048 - accuracy: 0.8561\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 541us/step - loss: 0.3984 - accuracy: 0.8611\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 514us/step - loss: 0.3932 - accuracy: 0.8598\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 495us/step - loss: 0.3872 - accuracy: 0.8725\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 519us/step - loss: 0.3801 - accuracy: 0.8674\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 455us/step - loss: 0.3740 - accuracy: 0.8813\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 530us/step - loss: 0.3674 - accuracy: 0.8750\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 515us/step - loss: 0.3599 - accuracy: 0.8902\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 492us/step - loss: 0.3535 - accuracy: 0.8939\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 507us/step - loss: 0.3472 - accuracy: 0.8914\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 513us/step - loss: 0.3411 - accuracy: 0.9040\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 519us/step - loss: 0.3375 - accuracy: 0.9028\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 507us/step - loss: 0.3299 - accuracy: 0.9116\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 513us/step - loss: 0.3256 - accuracy: 0.9053\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 517us/step - loss: 0.3179 - accuracy: 0.9154\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 520us/step - loss: 0.3120 - accuracy: 0.9192\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 515us/step - loss: 0.3050 - accuracy: 0.9205\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 477us/step - loss: 0.3030 - accuracy: 0.9167\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 505us/step - loss: 0.2951 - accuracy: 0.9205\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 539us/step - loss: 0.2879 - accuracy: 0.9268\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 501us/step - loss: 0.2826 - accuracy: 0.9280\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 539us/step - loss: 0.2782 - accuracy: 0.9331\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 493us/step - loss: 0.2720 - accuracy: 0.9331\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 532us/step - loss: 0.2675 - accuracy: 0.9356\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 538us/step - loss: 0.2619 - accuracy: 0.9394\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 573us/step - loss: 0.2579 - accuracy: 0.9432\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 511us/step - loss: 0.2535 - accuracy: 0.9495\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 581us/step - loss: 0.2491 - accuracy: 0.9508\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 525us/step - loss: 0.2418 - accuracy: 0.9495\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 545us/step - loss: 0.2373 - accuracy: 0.9558\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 515us/step - loss: 0.2352 - accuracy: 0.9571\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 465us/step - loss: 0.2285 - accuracy: 0.9634\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 506us/step - loss: 0.2235 - accuracy: 0.9634\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 496us/step - loss: 0.2203 - accuracy: 0.9659\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 534us/step - loss: 0.2160 - accuracy: 0.9710\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 507us/step - loss: 0.2109 - accuracy: 0.9710\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 460us/step - loss: 0.2075 - accuracy: 0.9684\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 475us/step - loss: 0.2035 - accuracy: 0.9722\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 531us/step - loss: 0.1990 - accuracy: 0.9735\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 530us/step - loss: 0.1938 - accuracy: 0.9747\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 496us/step - loss: 0.1902 - accuracy: 0.9773\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 490us/step - loss: 0.1889 - accuracy: 0.9710\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 518us/step - loss: 0.1834 - accuracy: 0.9785\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 508us/step - loss: 0.1799 - accuracy: 0.9823\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 520us/step - loss: 0.1755 - accuracy: 0.9823\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 533us/step - loss: 0.1719 - accuracy: 0.9848\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 526us/step - loss: 0.1686 - accuracy: 0.9861\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 503us/step - loss: 0.1644 - accuracy: 0.9886\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 467us/step - loss: 0.1624 - accuracy: 0.9874\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 527us/step - loss: 0.1589 - accuracy: 0.9912\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 479us/step - loss: 0.1550 - accuracy: 0.9899\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 519us/step - loss: 0.1517 - accuracy: 0.9924\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 493us/step - loss: 0.1490 - accuracy: 0.9937\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 451us/step - loss: 0.1463 - accuracy: 0.9924\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 520us/step - loss: 0.1425 - accuracy: 0.9949\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 536us/step - loss: 0.1404 - accuracy: 0.9912\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 510us/step - loss: 0.1381 - accuracy: 0.9962\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 500us/step - loss: 0.1347 - accuracy: 0.9937\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 478us/step - loss: 0.1312 - accuracy: 0.9962\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 579us/step - loss: 0.1285 - accuracy: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x2a146e9d0>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T08:10:30.714861Z",
     "start_time": "2023-08-02T08:10:29.080776Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "     binary_0  binary_1  binary_2  binary_3  binary_4  binary_5  binary_6  \\\n213       0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n331       0.0       0.0       0.0       1.0       1.0       0.0       0.0   \n501       1.0       0.0       0.0       0.0       0.0       1.0       0.0   \n309       1.0       0.0       0.0       0.0       1.0       0.0       0.0   \n88        0.0       0.0       1.0       0.0       1.0       0.0       0.0   \n..        ...       ...       ...       ...       ...       ...       ...   \n450       0.0       0.0       0.0       1.0       0.0       0.0       1.0   \n705       0.0       0.0       1.0       0.0       0.0       0.0       1.0   \n305       0.0       0.0       1.0       0.0       0.0       0.0       0.0   \n807       0.0       0.0       0.0       1.0       1.0       0.0       0.0   \n237       0.0       0.0       0.0       1.0       1.0       0.0       0.0   \n\n     binary_7  binary_8  binary_9  ...  binary_74  binary_75  binary_76  \\\n213       1.0       1.0       0.0  ...        0.0        0.0        0.0   \n331       0.0       0.0       0.0  ...        0.0        1.0        0.0   \n501       0.0       1.0       0.0  ...        1.0        0.0        1.0   \n309       0.0       0.0       1.0  ...        0.0        1.0        0.0   \n88        0.0       0.0       0.0  ...        0.0        0.0        0.0   \n..        ...       ...       ...  ...        ...        ...        ...   \n450       0.0       0.0       0.0  ...        1.0        0.0        0.0   \n705       0.0       0.0       1.0  ...        0.0        1.0        0.0   \n305       1.0       0.0       0.0  ...        0.0        1.0        0.0   \n807       0.0       0.0       0.0  ...        1.0        0.0        0.0   \n237       0.0       0.0       0.0  ...        1.0        0.0        0.0   \n\n     binary_77  binary_78  binary_79  binary_80  binary_81  binary_82  \\\n213        0.0        0.0        1.0        0.0        0.0        1.0   \n331        1.0        0.0        0.0        0.0        0.0        0.0   \n501        0.0        0.0        0.0        0.0        0.0        0.0   \n309        0.0        0.0        1.0        0.0        1.0        0.0   \n88         0.0        1.0        0.0        0.0        0.0        1.0   \n..         ...        ...        ...        ...        ...        ...   \n450        1.0        0.0        0.0        0.0        1.0        0.0   \n705        0.0        0.0        1.0        0.0        1.0        0.0   \n305        1.0        0.0        0.0        0.0        1.0        0.0   \n807        0.0        0.0        1.0        0.0        0.0        1.0   \n237        0.0        0.0        1.0        0.0        0.0        1.0   \n\n     binary_83  \n213        0.0  \n331        1.0  \n501        1.0  \n309        0.0  \n88         0.0  \n..         ...  \n450        0.0  \n705        0.0  \n305        0.0  \n807        0.0  \n237        0.0  \n\n[198 rows x 84 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>binary_0</th>\n      <th>binary_1</th>\n      <th>binary_2</th>\n      <th>binary_3</th>\n      <th>binary_4</th>\n      <th>binary_5</th>\n      <th>binary_6</th>\n      <th>binary_7</th>\n      <th>binary_8</th>\n      <th>binary_9</th>\n      <th>...</th>\n      <th>binary_74</th>\n      <th>binary_75</th>\n      <th>binary_76</th>\n      <th>binary_77</th>\n      <th>binary_78</th>\n      <th>binary_79</th>\n      <th>binary_80</th>\n      <th>binary_81</th>\n      <th>binary_82</th>\n      <th>binary_83</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>213</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>331</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>501</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>309</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>450</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>705</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>305</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>807</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>237</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>198 rows Ã— 84 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T08:11:26.674712Z",
     "start_time": "2023-08-02T08:11:26.672103Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 611us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.21043213],\n       [0.99032825],\n       [0.8749193 ],\n       [0.3487143 ],\n       [0.10357692],\n       [0.19297008],\n       [0.09535204],\n       [0.6313702 ],\n       [0.45531565],\n       [0.971308  ],\n       [0.5613442 ],\n       [0.10343919],\n       [0.06253915],\n       [0.9238348 ],\n       [0.7880002 ],\n       [0.20271587],\n       [0.0272734 ],\n       [0.66317976],\n       [0.991622  ],\n       [0.9980593 ],\n       [0.05974365],\n       [0.70568806],\n       [0.00372883],\n       [0.8588365 ],\n       [0.7193893 ],\n       [0.7653817 ],\n       [0.69815516],\n       [0.26301184],\n       [0.16565408],\n       [0.6504346 ],\n       [0.60843873],\n       [0.04590555],\n       [0.9192656 ],\n       [0.29931524],\n       [0.01075717],\n       [0.11219808],\n       [0.02724502],\n       [0.06630015],\n       [0.9638328 ],\n       [0.9837102 ],\n       [0.95083797],\n       [0.02672756],\n       [0.6080648 ],\n       [0.13799945],\n       [0.955758  ],\n       [0.91519314],\n       [0.6508672 ],\n       [0.37309873],\n       [0.99917555],\n       [0.6509251 ],\n       [0.5570521 ],\n       [0.04845768],\n       [0.10123263],\n       [0.908002  ],\n       [0.42754847],\n       [0.22752397],\n       [0.2396538 ],\n       [0.99980783],\n       [0.8163665 ],\n       [0.5819168 ],\n       [0.9931433 ],\n       [0.24255551],\n       [0.7535368 ],\n       [0.02186038],\n       [0.21093804],\n       [0.9788742 ],\n       [0.13038492],\n       [0.94209677],\n       [0.0040483 ],\n       [0.86668676],\n       [0.9432977 ],\n       [0.13404424],\n       [0.87804127],\n       [0.07932712],\n       [0.36087662],\n       [0.02910006],\n       [0.99712515],\n       [0.38512838],\n       [0.14832002],\n       [0.43011987],\n       [0.93280625],\n       [0.02302255],\n       [0.84092116],\n       [0.03818543],\n       [0.20256686],\n       [0.40967715],\n       [0.63525087],\n       [0.04781535],\n       [0.14659983],\n       [0.0188769 ],\n       [0.25948223],\n       [0.12982649],\n       [0.62764347],\n       [0.01801947],\n       [0.00843052],\n       [0.8662888 ],\n       [0.13311617],\n       [0.4002812 ],\n       [0.22035573],\n       [0.18078   ],\n       [0.4836917 ],\n       [0.05138668],\n       [0.635194  ],\n       [0.03536458],\n       [0.66971105],\n       [0.2376996 ],\n       [0.74380594],\n       [0.4108241 ],\n       [0.9525835 ],\n       [0.9698232 ],\n       [0.57865787],\n       [0.52459997],\n       [0.6243587 ],\n       [0.6693549 ],\n       [0.29556158],\n       [0.13826428],\n       [0.05954629],\n       [0.6409606 ],\n       [0.86278987],\n       [0.360211  ],\n       [0.1499606 ],\n       [0.62787217],\n       [0.04768636],\n       [0.8273358 ],\n       [0.82174766],\n       [0.57918483],\n       [0.2679636 ],\n       [0.99247   ],\n       [0.6064504 ],\n       [0.81841916],\n       [0.9588039 ],\n       [0.47554022],\n       [0.09492619],\n       [0.2859342 ],\n       [0.01777376],\n       [0.59886855],\n       [0.9717603 ],\n       [0.6799258 ],\n       [0.9620229 ],\n       [0.07751333],\n       [0.956233  ],\n       [0.439572  ],\n       [0.80590934],\n       [0.35424516],\n       [0.29191622],\n       [0.14261238],\n       [0.6609905 ],\n       [0.09476711],\n       [0.12832515],\n       [0.8606664 ],\n       [0.9354657 ],\n       [0.7022712 ],\n       [0.07174513],\n       [0.19516551],\n       [0.31732774],\n       [0.13762309],\n       [0.19208536],\n       [0.9920338 ],\n       [0.70726675],\n       [0.39511946],\n       [0.30378613],\n       [0.16979061],\n       [0.81543344],\n       [0.47794184],\n       [0.7405848 ],\n       [0.8339891 ],\n       [0.10194838],\n       [0.5209649 ],\n       [0.8436865 ],\n       [0.00787733],\n       [0.8322001 ],\n       [0.7034773 ],\n       [0.26820725],\n       [0.968231  ],\n       [0.81104785],\n       [0.9277727 ],\n       [0.365663  ],\n       [0.16382074],\n       [0.65028304],\n       [0.92275995],\n       [0.08529224],\n       [0.00505874],\n       [0.88371015],\n       [0.782976  ],\n       [0.12860665],\n       [0.18228815],\n       [0.02100553],\n       [0.67089397],\n       [0.612333  ],\n       [0.01656202],\n       [0.48453936],\n       [0.11421673],\n       [0.990937  ],\n       [0.987409  ],\n       [0.59383535],\n       [0.48818102],\n       [0.0032972 ],\n       [0.14708132]], dtype=float32)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T08:11:35.099779Z",
     "start_time": "2023-08-02T08:11:35.048317Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 616us/step\n",
      "7/7 [==============================] - 0s 586us/step\n"
     ]
    }
   ],
   "source": [
    "report = Report.create_report(model, (X_test, y_test), True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T08:36:58.051336Z",
     "start_time": "2023-08-02T08:36:57.846049Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note: Running TeX ...\n",
      "note: Rerunning TeX because \"ASD.aux\" changed ...\n",
      "note: Running xdvipdfmx ...\n",
      "note: Writing `ASD.pdf` (27.88 KiB)\n",
      "note: Skipped writing 1 intermediate files (use --keep-intermediates to keep them)\n"
     ]
    }
   ],
   "source": [
    "generate_latex_report(report, 'ASD', Path('.'), True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T08:37:01.201466Z",
     "start_time": "2023-08-02T08:36:59.359919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
