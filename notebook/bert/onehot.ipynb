{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFBertForSequenceClassification"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T14:18:43.662349Z",
     "start_time": "2024-03-21T14:18:43.592265Z"
    }
   },
   "id": "c6e44ccfaec72c1c",
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": [
    "from src.dataset import load_dataset, Species, Modification\n",
    "\n",
    "# from keras.layers import SimpleRNN, Dense, Embedding, Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T14:18:43.690736Z",
     "start_time": "2024-03-21T14:18:43.673384Z"
    }
   },
   "id": "a2d641410e08bfae",
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T14:18:44.857587Z",
     "start_time": "2024-03-21T14:18:43.693390Z"
    }
   },
   "id": "dff7fb1d2ad5af1a",
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = load_dataset(Species.human, Modification.psi)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T14:18:44.931718Z",
     "start_time": "2024-03-21T14:18:44.858742Z"
    }
   },
   "id": "511b2094428cbfd6",
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": "# [value[0] for value in train_data.samples.values] ",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T14:18:44.935419Z",
     "start_time": "2024-03-21T14:18:44.933662Z"
    }
   },
   "id": "42a3681d6ebbb289",
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": [
    "train_encodings = tokenizer([value[0] for value in train_data.samples.values], truncation=True, padding=True, max_length=41)\n",
    "# test_encodings = tokenizer(test_data.sequences, truncation=True, padding=True, max_length=41)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T14:18:48.196017Z",
     "start_time": "2024-03-21T14:18:44.936240Z"
    }
   },
   "id": "bde3bac41787590b",
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_data.targets\n",
    "))"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-21T14:18:49.235356Z",
     "start_time": "2024-03-21T14:18:48.197032Z"
    }
   },
   "id": "initial_id",
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": "model_bert = TFBertForSequenceClassification.from_pretrained('bert-base-cased')",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T14:18:51.614383Z",
     "start_time": "2024-03-21T14:18:49.236294Z"
    }
   },
   "id": "67a6cfadb8c5bba7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model_bert.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T14:22:08.204590Z",
     "start_time": "2024-03-21T14:22:08.182135Z"
    }
   },
   "id": "16a168b91f83f342",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x33c880d70>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[50], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5e-5\u001B[39m)\n\u001B[1;32m      2\u001B[0m loss \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlosses\u001B[38;5;241m.\u001B[39mSparseCategoricalCrossentropy(from_logits\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mmodel_bert\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maccuracy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/experiments/rna_modification/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1495\u001B[0m, in \u001B[0;36mTFPreTrainedModel.compile\u001B[0;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001B[0m\n\u001B[1;32m   1493\u001B[0m \u001B[38;5;66;03m# This argument got renamed, we need to support both versions\u001B[39;00m\n\u001B[1;32m   1494\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msteps_per_execution\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m parent_args:\n\u001B[0;32m-> 1495\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1496\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloss_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1500\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweighted_metrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweighted_metrics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrun_eagerly\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_eagerly\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[43m        \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_execution\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1503\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1504\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1505\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1506\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m   1507\u001B[0m         optimizer\u001B[38;5;241m=\u001B[39moptimizer,\n\u001B[1;32m   1508\u001B[0m         loss\u001B[38;5;241m=\u001B[39mloss,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1514\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   1515\u001B[0m     )\n",
      "File \u001B[0;32m~/Workspace/experiments/rna_modification/.venv/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Workspace/experiments/rna_modification/.venv/lib/python3.12/site-packages/tf_keras/src/optimizers/__init__.py:335\u001B[0m, in \u001B[0;36mget\u001B[0;34m(identifier, **kwargs)\u001B[0m\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m get(\n\u001B[1;32m    331\u001B[0m         config,\n\u001B[1;32m    332\u001B[0m         use_legacy_optimizer\u001B[38;5;241m=\u001B[39muse_legacy_optimizer,\n\u001B[1;32m    333\u001B[0m     )\n\u001B[1;32m    334\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 335\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    336\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not interpret optimizer identifier: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00midentifier\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    337\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x33c880d70>"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "source": [
    "model_bert.fit(train_dataset.shuffle(100).batch(32), epochs=3, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T14:22:09.771435Z",
     "start_time": "2024-03-21T14:22:09.639186Z"
    }
   },
   "id": "179f490630b97b74",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[51], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel_bert\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/experiments/rna_modification/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1161\u001B[0m, in \u001B[0;36mfit\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig \u001B[38;5;241m=\u001B[39m config\n\u001B[1;32m   1160\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname_or_path \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mname_or_path\n\u001B[0;32m-> 1161\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgeneration_config \u001B[38;5;241m=\u001B[39m GenerationConfig\u001B[38;5;241m.\u001B[39mfrom_model_config(config) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcan_generate() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1162\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_save_spec(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_signature)\n",
      "File \u001B[0;32m~/Workspace/experiments/rna_modification/.venv/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Workspace/experiments/rna_modification/.venv/lib/python3.12/site-packages/tf_keras/src/engine/training.py:3978\u001B[0m, in \u001B[0;36m_assert_compile_was_called\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "91cfe4f9f410cd70",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
