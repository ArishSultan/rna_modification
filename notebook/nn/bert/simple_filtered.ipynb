{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from torch import save\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "\n",
    "from src.dataset import load_dataset, Species, Modification\n",
    "from src.utils.transformers import encode_seq_bunch, make_dataloader, train_epoch, calculate_acc_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T17:36:36.832761Z",
     "start_time": "2024-10-06T17:36:34.248308Z"
    }
   },
   "id": "c6e44ccfaec72c1c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T17:36:36.838301Z",
     "start_time": "2024-10-06T17:36:36.836301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEVICE = 'mps'\n",
    "MODEL = 'bert-base-uncased'\n",
    "\n",
    "EXPERIMENT_NAME = 'bert-simple-filtered'"
   ],
   "id": "353f8ec4eba622cd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "tokenizer = BertTokenizerFast.from_pretrained(MODEL)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T17:36:37.982888Z",
     "start_time": "2024-10-06T17:36:36.932988Z"
    }
   },
   "id": "dff7fb1d2ad5af1a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arish/Research/research/rna_modification/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T17:36:38.004432Z",
     "start_time": "2024-10-06T17:36:37.996470Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_dataset(Species.human, Modification.psi, 'all')",
   "id": "bb4b5ebdadb20ea4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T17:36:38.437946Z",
     "start_time": "2024-10-06T17:36:38.012398Z"
    }
   },
   "cell_type": "code",
   "source": "sequences, labels = encode_seq_bunch(dataset, tokenizer, True)",
   "id": "db069f82796bbf4f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T17:36:38.451635Z",
     "start_time": "2024-10-06T17:36:38.446954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)"
   ],
   "id": "a8f686aef15da19a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T17:36:38.522586Z",
     "start_time": "2024-10-06T17:36:38.460142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataloader = make_dataloader(x_train, y_train)\n",
    "test_dataloader = make_dataloader(x_test, y_test)\n",
    "val_dataloader = make_dataloader(x_val, y_val)"
   ],
   "id": "d45f148e71d8366e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T17:36:40.632286Z",
     "start_time": "2024-10-06T17:36:38.531086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = BertForSequenceClassification.from_pretrained(MODEL, num_labels=2)\n",
    "model.to(DEVICE)\n",
    "\n",
    "None"
   ],
   "id": "6a2457412227b32c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T17:36:40.816080Z",
     "start_time": "2024-10-06T17:36:40.664283Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = AdamW(model.parameters(), lr=2e-5)",
   "id": "dd190cce7eb9ab18",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T17:36:40.827078Z",
     "start_time": "2024-10-06T17:36:40.825171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "old_val_acc = 0\n",
    "old_train_acc = 0\n",
    "old_model_name = ''"
   ],
   "id": "295b9f3f87df5bff",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T17:36:40.838194Z",
     "start_time": "2024-10-06T17:36:40.836301Z"
    }
   },
   "cell_type": "code",
   "source": "TOTAL_EPOCHS = 0",
   "id": "b7a0d488abd7c47d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in range(1, 5 + 1):\n",
    "    TOTAL_EPOCHS += 1\n",
    "\n",
    "    train_acc, val_acc = train_epoch(TOTAL_EPOCHS, DEVICE, model, optimizer, train_dataloader, val_dataloader)\n",
    "    if train_acc > old_train_acc and val_acc > old_val_acc:\n",
    "        if old_model_name != '':\n",
    "            os.unlink(old_model_name)\n",
    "        old_val_acc = val_acc\n",
    "        old_train_acc = train_acc\n",
    "        old_model_name = f'{EXPERIMENT_NAME}_ep-{TOTAL_EPOCHS}_tacc-{train_acc:.2}_vacc-{val_acc:.2}.pt'\n",
    "        save(model, old_model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T17:48:38.594056Z",
     "start_time": "2024-10-06T17:44:27.346431Z"
    }
   },
   "id": "bde3bac41787590b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "697e0b7739a34c809dca841bd93f1ea3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "537a9d7e3a02406383bd6e426e21ec84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aab66e3e0b6f40648e7b6f344bd312e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85e3416603644fda847b0c2d5114dd09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9fcbec0065714c21849fe646c73537f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T17:51:35.723826Z",
     "start_time": "2024-10-06T17:51:30.992832Z"
    }
   },
   "cell_type": "code",
   "source": "calculate_acc_dataset(DEVICE, model, test_dataloader)",
   "id": "5b750f0252641842",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73502722323049"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T17:41:14.679003Z",
     "start_time": "2024-10-06T17:41:14.677505Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "26128601b4784a84",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
